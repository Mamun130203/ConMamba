<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ConMamba: Contrastive Vision Mamba for Plant Disease Detection</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ConMamba: Contrastive Vision Mamba for Plant Disease Detection</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sites.google.com/view/aamamunswebsite/home?authuser=0" target="_blank">Abdullah Al Mamun<sup>a,b*</sup></a>, <a href="https://people.csiro.au/Z/M/miaohua-zhang" target="_blank">Miaohua Zhang</a>, <a href="https://people.csiro.au/a/d/david-ahmedtaristizabal" target="_blank">David Ahmedt-Aristizabal</a>, <a href="https://people.csiro.au/h/z/zeeshan-hayder" target="_blank">Zeeshan Hayder</a>, <a href="https://experts.griffith.edu.au/8866-mohammad-awrangjeb" target="_blank">Mohammad Awrangjeb</b>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors"style="color: black;">
                    <span class="author-block"style="color: black;"><sup>a</sup>Data61, CSIRO<br><sup>b</sup>Griffith University</span>
                  </div>

                  <div class="publication-links" style="display: flex; justify-content: center; gap: 10px;">
                    <!-- Paper link -->
                    <a href="https://ieeexplore.ieee.org/document/10869604" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>

                    <!-- ArXiv link with icon -->
                    <a href="https://arxiv.org/abs/your-arxiv-id" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>ArXiv</span>
                    </a>
                  </div>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


 <!-- Result Images with Captions -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered"></h2>

    <div class="content">
      <figure>
        <img src="static/images/method.png" alt="TOA Radiance Visualization">
        <figcaption class="has-text-centered">
          <strong>Figure 1:</strong> Schematic representation of the ConMamba framework. The framework begins with Stage 1 (Contrastive data augmentation): Data augmentation is applied to input images to generate two distinct augmented views for each input image. Stage 2 (Feature representation with Vision Mamba): Each augmented view undergoes patch embedding followed by the Vision Mamba Encoder (VME) to obtain meaningful bidirectional feature representations. Stage 3 (Loss calculation): A dual-level Contrastive loss with dynamic weight adjustment is employed to maximize local pairwise similarity (intra-class contrast) and global alignment (inter-class contrast). Finally, Stage 4 (Plant disease classification): The plant disease classification task adapts the learned representations for plant disease classification, utilizing the embedding vectors to produce class predictions.
        </figcaption>
      </figure>

      <!-- Add more figures here as needed -->
    </div>
  </div>
</section>
  
<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Plant Disease Detection (PDD) is a key aspect of precision agriculture. However, existing deep learning methods often rely on extensively annotated datasets, which are time-consuming and costly to generate. Self-supervised Learning (SSL) offers a promising alternative by exploiting the abundance of unlabeled data. However, most existing SSL approaches suffer from high computational costs due to convolutional neural networks or transformer-based architectures. Additionally, they struggle to capture long-range dependencies in visual representation and rely on static loss functions that fail to align local and global features effectively. To address these challenges, we propose ConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates the Vision Mamba Encoder (VME), which employs a bidirectional State Space Model (SSM) to capture long-range dependencies efficiently. Furthermore, we introduce a dual-level contrastive loss with dynamic weight adjustment to optimize local-global feature alignment. Experimental results on three benchmark datasets demonstrate that ConMamba significantly outperforms state-of-the-art methods across multiple evaluation metrics. This provides an efficient and robust solution for PDD.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Problems Carousel -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Problems</h2>
    <div id="problems-carousel" class="carousel results-carousel">

      <!-- Problem Figure 1 -->
      <div class="item has-text-centered">
        <img src="static/images/comparison.png" alt="TOA Radiance Visualization"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 2:</strong> Comparison of different architecture designs: (a) CNN, (b) ViT, and (c) Vision Mamba, emphasizing their capacities to capture short-range and long-range dependencies.
        </h2>
      </div>

      <!-- Problem Figure 2 -->
      <div class="item has-text-centered">
        <img src="static/images/sample.png" alt="Atmospheric Correction Visualization"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 2b:</strong> Atmospheric correction removes distortions to recover 
          accurate surface reflectance, which is critical for reliable analysis on resource-constrained platforms.
        </h2>
      </div>

    </div>
  </div>
</section>



<!-- Table Results Carousel -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Quantitative Results</h2>
    <div id="table-carousel" class="carousel results-carousel">

      <!-- Table 1 -->
      <div class="item has-text-centered">
        <img src="static/images/table1.png" alt="Performance Table 1"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Table 1:</strong> Performance comparison of ConMamba with existing baseline methods on the test datasets.
        </h2>
      </div>

      <!-- Table 2 -->
      <div class="item has-text-centered">
        <img src="static/images/table2.png" alt="Performance Table 2"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Table 2:</strong> Performance comparison of Vision Mamba and traditional encoder using dual-level contrastive loss on the
PlantVillage dataset.
        </h2>
      </div>

      <!-- Table 3 -->
      <div class="item has-text-centered">
        <img src="static/images/table3.png" alt="Performance Table 3"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Table 3:</strong> Performance comparison of Vision Mamba and traditional encoder using dual-level contrastive loss on the PlantDoc dataset.
        </h2>
      </div>

      <!-- Table 4 -->
      <div class="item has-text-centered">
        <img src="static/images/table4.png" alt="Performance Table 4"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Table 4:</strong>  Performance comparison of Vision Mamba and traditional encoder using dual-level contrastive loss on the Citrus
dataset.
        </h2>
      </div>

    </div>
  </div>
</section>



<!-- Visual Results Carousel -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Qualitative Visualizations</h2>
    <div id="visual-carousel" class="carousel results-carousel">

      <!-- Visual 1 -->
      <div class="item has-text-centered">
        <img src="static/images/v1.png" alt="Visual Result 1"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 3a:</strong> Visualization of activation maps for randomly chosen images from the PlantVillage, PlantDoc, and Citrus datasets.
        </h2>
      </div>

      <!-- Visual 2 -->
      <div class="item has-text-centered">
        <img src="static/images/v2.png" alt="Visual Result 2"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 3b:</strong> t-SNE visualization of feature representations learned by ConMamba on corn plant images from the PlantVillage dataset.
        </h2>
      </div>

      <!-- Visual 3 -->
      <div class="item has-text-centered">
        <img src="static/images/v3.png" alt="Visual Result 3"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 3c:</strong>  t-SNE visualization of feature representations learned by ConMamba on corn plant images from the PlantDoc
dataset.
        </h2>
      </div>

      <!-- Visual 4 -->
      <div class="item has-text-centered">
        <img src="static/images/v4.png" alt="Visual Result 4"
             style="max-width: 100%; height: auto;" />
        <h2 class="subtitle has-text-centered mt-4">
          <strong>Figure 3d:</strong> t-SNE visualization of feature representations learned by ConMamba on the Citrus dataset.
        </h2>
      </div>

    </div>
  </div>
</section>




<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/images/AC_project.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        International Conference on Digital Image Computing: Techniques and Applications (DICTA 2024) Nov 27-29, 2024, Perth, Australia” 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->


<!-- BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{mamun2025conmambacontrastivevisionmamba,
  title={ConMamba: Contrastive Vision Mamba for Plant Disease Detection}, 
  author={Abdullah Al Mamun and Miaohua Zhang and David Ahmedt-Aristizabal and Zeeshan Hayder and Mohammad Awrangjeb},
  year={2025},
  eprint={2506.03213},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2506.03213}}</code></pre>
  </div>
</section>

<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
